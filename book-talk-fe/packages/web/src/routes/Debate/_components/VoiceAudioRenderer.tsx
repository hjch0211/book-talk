import { useEffect, useRef } from 'react';
import { useVoiceChat } from '../../../hooks/useVoiceChat';

/**
 * WebRTCë¡œ ìˆ˜ì‹ í•œ ì›ê²© ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì¬ìƒí•˜ëŠ” ì»´í¬ë„ŒíŠ¸
 * - ê° ì°¸ê°€ìë§ˆë‹¤ ìˆ¨ê²¨ì§„ <audio> ì—˜ë¦¬ë¨¼íŠ¸ë¥¼ ìƒì„±
 * - remoteStreamì„ ìë™ìœ¼ë¡œ ì¬ìƒ
 */
export function VoiceAudioRenderer() {
    const { participants, getRemoteStream } = useVoiceChat();

    console.log('ğŸµ VoiceAudioRenderer: Current participants:', participants);

    return (
        <>
            {participants.map(participant => (
                <RemoteAudio
                    key={participant.accountId}
                    participantId={participant.accountId}
                    participantName={participant.accountName}
                    getRemoteStream={getRemoteStream}
                />
            ))}
        </>
    );
}

interface RemoteAudioProps {
    participantId: string;
    participantName: string;
    getRemoteStream: (id: string) => MediaStream | null;
}

function RemoteAudio({ participantId, participantName, getRemoteStream }: RemoteAudioProps) {
    const audioRef = useRef<HTMLAudioElement>(null);

    useEffect(() => {
        const stream = getRemoteStream(participantId);

        if (!audioRef.current) {
            console.warn(`âš ï¸ Audio ref not ready for ${participantName} (${participantId})`);
            return;
        }

        if (stream) {
            console.log(`ğŸµ Setting audio stream for ${participantName} (${participantId})`, {
                streamId: stream.id,
                tracks: stream.getTracks().map(t => ({
                    kind: t.kind,
                    enabled: t.enabled,
                    readyState: t.readyState
                }))
            });

            audioRef.current.srcObject = stream;

            // ìë™ ì¬ìƒ ì‹œë„
            audioRef.current.play()
                .then(() => {
                    console.log(`âœ… Audio playing for ${participantName} (${participantId})`);
                })
                .catch(err => {
                    console.error(`âŒ Audio play failed for ${participantName} (${participantId}):`, err);
                    // ì‚¬ìš©ì ì¸í„°ë™ì…˜ì´ í•„ìš”í•œ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì—ëŸ¬ ë¡œê·¸
                    if (err.name === 'NotAllowedError') {
                        console.warn('User interaction may be required to play audio');
                    }
                });
        } else {
            console.log(`â„¹ï¸ No stream available for ${participantName} (${participantId})`);
            audioRef.current.srcObject = null;
        }

        // Cleanup
        return () => {
            if (audioRef.current) {
                console.log(`ğŸ§¹ Cleaning up audio for ${participantName} (${participantId})`);
                audioRef.current.pause();
                audioRef.current.srcObject = null;
            }
        };
    }, [participantId, participantName, getRemoteStream]);

    return (
        <audio
            ref={audioRef}
            autoPlay
            playsInline
            style={{ display: 'none' }}
            data-participant-id={participantId}
            data-participant-name={participantName}
        />
    );
}
